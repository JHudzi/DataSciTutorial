{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Josh Hudziak - C00231846\n",
    "* Lecturer: Greg Doyle\n",
    "* Purpose: Display Machine learning techniques and algorithms on a dataset\n",
    "* Date: 23rd April 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This is a tutorial to demonstrate data pre-processing and machine learning throiugh the use of Jupyter Notebook. In this Notebook olypic data will be used for pre processing and titanic data will be used for machine learning modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 major points in Data Preprocessing. They are as follows;\n",
    "1. Your Dataset must be split into Training data and Test data.\n",
    "2. You must do something about missing values.\n",
    "3. You must be able to operate on catagorical data.\n",
    "4. The Dataset must then be normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://github.com/rashida048/Datasets/blob/master/olympics.csv\" target=\"Olympic\">Olympic Dataset</a>\n",
    "2. <a href=\"https://github.com/rashida048/Datasets/blob/master/titanic_data.csv\" target=\"Titanic\">Titanic Dataset</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before anywork can be done we must import our libraries. The most useful libraries are;\n",
    "* SkLearn\n",
    "* Pandas: Useful for importing and pre-processing datasets\n",
    "* Numpy\n",
    "* Matplotlib: Plot nice charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most datasets are split into two **Features** and **Dependant Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympicsDataset = pd.read_csv(\"file:///C:/Users/Josh/Documents/4th Year Docs/Data Sci/olympics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.earthdatascience.org/courses/intro-to-earth-data-science/file-formats/use-text-files/format-text-with-markdown-jupyter-notebook/\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
